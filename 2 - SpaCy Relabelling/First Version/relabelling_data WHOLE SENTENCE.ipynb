{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leung Wai Liu <br>\n",
    "JPMC <br>\n",
    "July 25, 2022 <br>\n",
    "Twitter Relabelling WHOLE SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wordninja\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('logs/combined_final.tsv', sep='\\t')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing all @user to be B-PER for now\n",
    "new_label = combined_df['NER Label'].tolist()\n",
    "new_pos = combined_df['POS Label'].tolist()\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "    # retrieving the word of a particular row\n",
    "    particular_word = row['Word']\n",
    "\n",
    "    # retrieving the word index in the tweet for verification\n",
    "    particular_start_index = row['Word Index']\n",
    "    \n",
    "    original_sentence = row['Tweet']\n",
    "    original_sentence_split = original_sentence.split(' ')\n",
    "    # print(original_sentence_split)\n",
    "\n",
    "    is_hashtag = False\n",
    "    encode = ''\n",
    "    encode_len = 0\n",
    "    to_feed_sentence = original_sentence\n",
    "    to_feed_split = original_sentence_split\n",
    "    for word in range(len(to_feed_split))\n",
    "    \n",
    "    \n",
    "    # if a particular word is a user tag - label it has a person\n",
    "    if '@user' in particular_word:\n",
    "        new_label[index] = 'B-PER'\n",
    "        new_pos[index] = 'User: No change'\n",
    "    else:\n",
    "        # if there is a hashtag in a particular word, cut out the hashtag to do further processing\n",
    "        if '#' in particular_word:\n",
    "            particular_word = particular_word[1:]\n",
    "            is_hashtag = True\n",
    "\n",
    "        # breaking the word into phrases with Viterbo splitting (WordNinja)\n",
    "        if is_hashtag == True: \n",
    "            encode = wordninja.split(particular_word)\n",
    "            encode_len = len(encode)\n",
    "            # print('ENCODE LEN FOR HASHTAG:', encode_len)\n",
    "            to_feed_split = original_sentence_split[:(particular_start_index-1)] + encode + original_sentence_split[particular_start_index:]\n",
    "            to_feed_sentence = ' '.join(to_feed_split)\n",
    "            # print('TO FEED SENTENCE', to_feed_sentence)\n",
    "        else:\n",
    "            # if not hashtag, then we keep the particular word in the encode and the original sentence split \n",
    "            # (breaking one word apart into letters might result in worse results) \n",
    "            encode = particular_word\n",
    "            encode_len = len(encode.split(' '))\n",
    "\n",
    "        # encoding into spacy document to get the NER entity of each word\n",
    "        sentence_doc = nlp(to_feed_sentence) # splitted word phrase\n",
    "        word_entities = [(e.text, e.ent_iob_, e.ent_type_, e.pos_) for e in sentence_doc]\n",
    "\n",
    "        # check if the length of the entities that fed in matches with the len of entities that came out\n",
    "        print('-' * 50)\n",
    "        print('Original Particular word')\n",
    "        print(particular_word)\n",
    "        print('To feed sentence')\n",
    "        print(to_feed_sentence)\n",
    "        print('To feed split')\n",
    "        print(to_feed_split)\n",
    "        print('Word Entities result')\n",
    "        print(word_entities)\n",
    "        print(\"IF LENGTH MATCH AFTER SPACY PASS:\", len(word_entities) == len(to_feed_split))\n",
    "        print('-' * 50)\n",
    "  \n",
    "        # retrieving all the labels and pos tags from each phrase (if any)\n",
    "        label = []\n",
    "        pos = []\n",
    "\n",
    "        word_entities_to_verify = word_entities[particular_start_index : (particular_start_index + encode_len)]\n",
    "        print(\"PARTICULAR WORD\", particular_word)\n",
    "        print(\"WORD ENTITIES TO VERIFY\", word_entities_to_verify)\n",
    "        \n",
    "        # otherwise append all of the NER tags from the split word entity (if there are)\n",
    "        for numents in range(len(word_entities_to_verify)):\n",
    "            if word_entities_to_verify[numents][2] != '':\n",
    "                label.append(word_entities_to_verify[numents][2])\n",
    "            pos.append(word_entities_to_verify[numents][3])\n",
    "        \n",
    "        print(label)\n",
    "        print(pos)\n",
    "        exit()\n",
    "        # Filtering - if the label list is not empty: \n",
    "        if label != []:\n",
    "            # Find the most common label tagging\n",
    "            label_counter = Counter(label)\n",
    "            label_most_common = (label_counter.most_common(1))[0][0]\n",
    "            \n",
    "            # checking the label itself and then labeling it based on the Tweebank labelling standard\n",
    "            if label_most_common == 'PERSON':\n",
    "                new_label[index] = 'B-PER'\n",
    "            elif label_most_common == 'FAC':\n",
    "                new_label[index] = 'B-LOC'\n",
    "            elif label_most_common == 'NORP':\n",
    "                new_label[index] = 'B-ORG'\n",
    "            elif label_most_common == 'ORG':\n",
    "                new_label[index] = 'B-ORG'\n",
    "            elif label_most_common != 'MONEY' or label_most_common != 'QUANTITY':\n",
    "                new_label[index] = 'B-MISC'\n",
    "\n",
    "            pos_counter = Counter(pos)\n",
    "            pos_most_common = (pos_counter.most_common(1)[0][0])\n",
    "            new_pos[index] = pos_most_common\n",
    "            \n",
    "        else: \n",
    "            # If label list is empty, Looking through pos taggings to see if we can classify anything\n",
    "            # if there is a proper noun, then it can still be classified as miscellaneous\n",
    "            if 'PROPN' in pos: \n",
    "                new_label[index] = 'B-MISC'\n",
    "                new_pos[index] = 'PROPN'\n",
    "            elif 'NOUN' in pos:\n",
    "                new_label[index] = 'B-MISC'\n",
    "                new_pos[index] = 'NOUN'\n",
    "            else:\n",
    "                # if it is not able to find a label, then we find what SPACY thinks the POS tagging is\n",
    "                pos_counter = Counter(pos)\n",
    "                pos_most_common = (pos_counter.most_common(1)[0][0])\n",
    "                new_pos[index] = pos_most_common\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = combined_df\n",
    "new_df['Spacy POS Label'] = new_pos\n",
    "new_df['Spacy NER Label'] = new_label\n",
    "\n",
    "new_df = new_df.reindex(columns = ['Word', 'POS Label', 'NER Label', 'Spacy POS Label', 'Spacy NER Label', 'Tweet'])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('logs/relabelled_data_spacy_pass.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
